{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cfgzb-vm2-XFW-508'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import exrex\n",
    "\n",
    "def rand_blocks(len=2, regex=\"[a-z]{3}:\\d{3}\"):\n",
    "    return\n",
    "\n",
    "exrex.getone('[a-z]{5}-([a-z]|\\d){3}-[A-Z]{3}-\\d{3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[5, 90]\n",
      "       x      y\n",
      "0   14.0    NaN\n",
      "1   43.0    NaN\n",
      "2   98.0    NaN\n",
      "3   11.0    NaN\n",
      "4   73.0    NaN\n",
      "..   ...    ...\n",
      "95  33.0    NaN\n",
      "96  46.0    NaN\n",
      "97   3.0  247.0\n",
      "98   6.0    NaN\n",
      "99  85.0    NaN\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import exrex\n",
    "\n",
    "df = pd.DataFrame({\"x\" : [random.randint(0,100) for x in range(100)], \"y\":[random.randint(200,300) for y in range(100)]})\n",
    "\n",
    "def distribute_nans(df, percent=[5,10]):\n",
    "    if isinstance(percent, list): \n",
    "        nan_prop = [round(np.floor(df.size * (x/100))) for x in percent]\n",
    "    else:\n",
    "        nan_prop = round(np.floor(df.size * (percent/100)))\n",
    "\n",
    "    for i, prop in enumerate(nan_prop):\n",
    "        df_temp = df.iloc[:,i:i+1].sample(frac=1)\n",
    "        print(df_temp.iloc[0:prop, :].apply(lambda x: np.nan, axis=1))\n",
    "        print(df_temp)\n",
    "    return\n",
    "\n",
    "def distribute_nans(df, percent=[5,10]):\n",
    "    if isinstance(percent, list): \n",
    "        print(df.size)\n",
    "        nan_prop = [round(len(df) * (x/100)) for x in percent]\n",
    "        print(nan_prop)\n",
    "    else:\n",
    "        nan_prop = round(len(df) * (percent/100))\n",
    "        print(nan_prop)\n",
    "\n",
    "    for i, prop in enumerate(nan_prop):       \n",
    "        change = df.iloc[:,i:i+1].sample(frac=1).index[0:prop]\n",
    "        df.iloc[change, i:i+1] = np.nan\n",
    "        df.sort_index()\n",
    "    return df\n",
    "\n",
    "df_nan = distribute_nans(df)\n",
    "\n",
    "print(df_nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paddy/miniconda3/envs/radian/lib/python3.11/site-packages/geopandas/io/file.py:399: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  as_dt = pd.to_datetime(df[k], errors=\"ignore\")\n",
      "/tmp/ipykernel_9247/1202543704.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"geometry:\", row[1][0])\n",
      "/tmp/ipykernel_9247/1202543704.py:62: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  lat = row[1][0].y\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[249], line 174\u001b[0m\n\u001b[1;32m    172\u001b[0m paris_null \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/paddy/git/radian/geojson_polygons/GeoJSON/null_testing.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m paris_null \u001b[38;5;241m=\u001b[39m paris_null[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPKID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousePrice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostCode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergyRating\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurveyTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreetName\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m--> 174\u001b[0m gdf_to_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql_revamp\u001b[39m\u001b[38;5;124m\"\u001b[39m, paris_null, random_var, rand_var_types, rand_var_names, extra_var, extra_var_types, extra_var_name, extra_var_dict, directory)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(paris_null)\n",
      "Cell \u001b[0;32mIn[249], line 62\u001b[0m, in \u001b[0;36mgdf_to_sql\u001b[0;34m(table_name, gdf, random_var, rand_var_types, rand_var_names, extra_var, extra_var_types, extra_var_name, extra_var_dict, directory)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m gdf\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Set 'y' value to Latitude and 'x' value to Longitude.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry:\u001b[39m\u001b[38;5;124m\"\u001b[39m, row[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 62\u001b[0m     lat \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m     63\u001b[0m     lon \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Pull the randomly generated strings and ints from the dataframe\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'y'"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "def get_var_type(var_type):\n",
    "    if var_type == 'int':\n",
    "        return \"INTEGER\"\n",
    "    elif var_type == 'str':\n",
    "        return \"VARCHAR\"\n",
    "    elif var_type == 'regex':\n",
    "        return \"VARCHAR\"\n",
    "    elif var_type == 'ts':\n",
    "        return \"TIMESTAMP\"\n",
    "\n",
    "def gdf_to_sql(table_name, gdf, random_var, rand_var_types, rand_var_names, extra_var, extra_var_types, extra_var_name, extra_var_dict, directory):\n",
    "    \n",
    "    # Opens up an SQL file based on the table name, writes to the file and closes it\n",
    "    sqlFile = open(f'{directory}/SQL/{table_name}.sql', \"w\")\n",
    "    sqlFile.write(\"\")\n",
    "    sqlFile.close()\n",
    "\n",
    "    # Opens up the SQL file to append lines to it\n",
    "    sqlFile = open(f'{directory}/SQL/{table_name}.sql', \"a\")\n",
    "\n",
    "    # SQL statments to create the table as well as drop if exists the table are appended\n",
    "    sqlFile.write('-- This is an automatically generated SQL table. This has been generated by the RADIAN tool (developer Mr. Paddy Gorry)\\n\\n')\n",
    "\n",
    "    sqlFile.write('DROP TABLE IF EXISTS {}; \\n\\n'.format(table_name))\n",
    "\n",
    "    sqlFile.write('CREATE TABLE {} ( \\n'.format(table_name))\n",
    "    sqlFile.write('\\tpkid SERIAL PRIMARY KEY NOT NULL, \\n')\n",
    "    sqlFile.write(\"\\tthegeom GEOMETRY DEFAULT ST_GeomFromText('POINT(0,51)', 4326)\")\n",
    "\n",
    "    if random_var:\n",
    "        sqlFile.write(',\\n')\n",
    "        for count, type in enumerate(rand_var_types):\n",
    "            sqlFile.write(f'\\t{rand_var_names[count]} {get_var_type(rand_var_types[count])}')\n",
    "            if count < len(rand_var_types)-1:\n",
    "                sqlFile.write(', \\n')\n",
    "\n",
    "    if extra_var:\n",
    "        for variable in extra_var_dict:\n",
    "            create_query = f\",\\n\\t{variable['name']} \"\n",
    "            if variable['type'] == 'str':\n",
    "                create_query += 'VARCHAR'\n",
    "            elif variable['type'] == 'regex':\n",
    "                create_query += 'VARCHAR'\n",
    "            elif variable['type'] == 'int':\n",
    "                create_query += 'INTEGER'\n",
    "            sqlFile.write(create_query)\n",
    "\n",
    "    sqlFile.write('\\n); \\n\\n')\n",
    "\n",
    "    sqlFile.write('-- Spatial index is now created\\n\\n')\n",
    "\n",
    "    # Creation of Spatial Index for the SQL file\n",
    "    sqlFile.write('CREATE INDEX {}_spatial_index ON {} USING gist (thegeom); \\n'.format(table_name, table_name))\n",
    "\n",
    "    # Loop through every point in the GeoDataFrame to write an instert statement to append to the SQL file\n",
    "    for row in gdf.iterrows():\n",
    "        # Set 'y' value to Latitude and 'x' value to Longitude.\n",
    "        print(\"geometry:\", row[1][0])\n",
    "        lat = row[1][0].y\n",
    "        lon = row[1][0].x\n",
    "        # Pull the randomly generated strings and ints from the dataframe\n",
    "        if random_var:\n",
    "            if (not extra_var):\n",
    "                query = f\"INSERT into {table_name} (thegeom, \"\n",
    "                for count, type in enumerate(rand_var_names):\n",
    "                    query += f\"{rand_var_names[count]}\"\n",
    "                    if count < len(rand_var_names)-1:\n",
    "                        query += \", \"\n",
    "                query += f\") VALUES (ST_SetSRID(ST_MakePoint({lon},{lat}), 4326), \"\n",
    "                for count, type in enumerate(rand_var_types):\n",
    "                    # 19/11/2024 - adding in NULL functionality\n",
    "                    current_value = row[1][count+1]\n",
    "                    if np.isnan(current_value):\n",
    "                        query += f'{current_value}'\n",
    "                    else:\n",
    "                        if type != \"int\":\n",
    "                            query += \"'\"\n",
    "                        query += f'{current_value}'\n",
    "                        if type != \"int\":\n",
    "                            query += \"'\"\n",
    "                    if count < len(rand_var_names)-1:\n",
    "                        query += \", \"\n",
    "                query += '); \\r'           \n",
    "\n",
    "            else:\n",
    "                full_var_names = rand_var_names + extra_var_name\n",
    "                full_var_types = rand_var_types + extra_var_types\n",
    "\n",
    "                extra_values = []\n",
    "                for i in range(len(extra_var_name)):\n",
    "                    extra_values.append(row[1][len(rand_var_names)+i])\n",
    "\n",
    "                query = f\"INSERT into {table_name} (thegeom, \"\n",
    "                for count, type in enumerate(full_var_names):\n",
    "                    query += f\"{full_var_names[count]}\"\n",
    "                    if count < len(full_var_names)-1:\n",
    "                        query += \", \"\n",
    "                query += f\") VALUES (ST_SetSRID(ST_MakePoint({lon},{lat}), 4326), \"\n",
    "                for count, type in enumerate(full_var_types):\n",
    "                    current_value = row[1][count+1]\n",
    "                    if np.isnan(current_value):\n",
    "                        query += f'{current_value}'\n",
    "                    else:\n",
    "                        if type != \"int\":\n",
    "                            query += \"'\"\n",
    "                    \n",
    "                        if type == \"str\":\n",
    "                            query += \"{}\".format(current_value.replace(\"'\", \"''\")) \n",
    "                        else:\n",
    "                            query += \"{}\".format(current_value)\n",
    "                    \n",
    "                        if type != \"int\":\n",
    "                            query += \"'\"\n",
    "                    if count < len(full_var_names)-1:\n",
    "                        query += \", \"\n",
    "                query += '); \\r'\n",
    "\n",
    "        else:\n",
    "            if(not extra_var):\n",
    "                # Insert statement for each point along with the included variables\n",
    "                query = \"INSERT into {} (thegeom) VALUES (ST_SetSRID(ST_MakePoint({},{}),4326)); \\r\".format(\n",
    "                    table_name, lon, lat)\n",
    "            else:\n",
    "                extra_values = []\n",
    "                for i in range(len(extra_var_name)):\n",
    "                    extra_values.append(row[1][i+1])\n",
    "\n",
    "                var_index = 1\n",
    "                query = f\"INSERT into {table_name} (thegeom, \"\n",
    "                for count, type in enumerate(extra_var_name):\n",
    "                    query += f\"{extra_var_name[count]}\"\n",
    "                    if count < len(extra_var_name)-1:\n",
    "                        query += \", \"\n",
    "                query += f\") VALUES (ST_SetSRID(ST_MakePoint({lon},{lat}), 4326), \"\n",
    "                for count, type in enumerate(extra_var_types):\n",
    "                    if type != \"int\":\n",
    "                        query += \"'\"\n",
    "                    \n",
    "                    if type == \"str\":\n",
    "                        query += \"{}\".format(row[1][count+1].replace(\"'\", \"''\")) \n",
    "                    else:\n",
    "                        query += \"{}\".format(row[1][count+1])\n",
    "                    \n",
    "                    if type != \"int\":\n",
    "                        query += \"'\"\n",
    "                    if count < len(extra_var_name)-1:\n",
    "                        query += \", \"\n",
    "                query += '); \\r'\n",
    "\n",
    "        # Write query string to SQL file\n",
    "        sqlFile.write(query)\n",
    "\n",
    "directory = os.path.dirname(\"geojson_polygons/paris.geojson\")\n",
    "\n",
    "random_var = True\n",
    "random_var_dict = [{\"type\":\"int\", \"name\": \"housePrice\", \"params\": [150000,2500000]},\n",
    "\t\t\t    {\"type\":\"regex\", \"name\": \"postCode\", \"params\": \"[a-zA-Z]{2}\\\\d{5}\"},\n",
    "\t\t\t\t{\"type\":\"regex\", \"name\": \"energyRating\", \"params\": \"[A-F]\"},\n",
    "\t\t\t\t{\"type\":\"ts\", \"name\": \"surveyTime\", \"params\": [\"2022-01-01 00:00:00\", \"2025-12-31 23:59:59\"] }]\n",
    "rand_var_types = [var_dict[\"type\"] for var_dict in random_var_dict]\n",
    "rand_var_names = [var_dict[\"name\"] for var_dict in random_var_dict]\n",
    "rand_var_params = [var_dict[\"params\"] for var_dict in random_var_dict]\n",
    "\n",
    "extra_var = True\n",
    "extra_var_dict = [{\"type\":\"str\", \"name\": \"streetName\", \"source\": \"street_names.csv\"}]\n",
    "extra_var_types = [var_dict[\"type\"] for var_dict in extra_var_dict]\n",
    "extra_var_name = [var_dict[\"name\"] for var_dict in extra_var_dict]\n",
    "\n",
    "paris_null = gpd.read_file('/home/paddy/git/radian/geojson_polygons/GeoJSON/null_testing.geojson')\n",
    "paris_null = paris_null[['PKID', 'geometry', 'housePrice', 'postCode', 'energyRating', 'surveyTime', 'streetName']]\n",
    "gdf_to_sql(\"sql_revamp\", paris_null, random_var, rand_var_types, rand_var_names, extra_var, extra_var_types, extra_var_name, extra_var_dict, directory)\n",
    "\n",
    "print(paris_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paddy/miniconda3/envs/radian/lib/python3.11/site-packages/geopandas/io/file.py:399: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  as_dt = pd.to_datetime(df[k], errors=\"ignore\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 77\u001b[0m\n\u001b[1;32m     73\u001b[0m         [sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(row\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m);\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     75\u001b[0m     test_row\u001b[38;5;241m.\u001b[39mapply(write_insert, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)       \n\u001b[0;32m---> 77\u001b[0m gdf_to_sql_new(paris_null, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql_test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m test \u001b[38;5;241m=\u001b[39m [(paris_null[paris_null\u001b[38;5;241m.\u001b[39mcolumns[x]]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(paris_null\u001b[38;5;241m.\u001b[39mcolumns))]\n\u001b[1;32m     80\u001b[0m test_row \u001b[38;5;241m=\u001b[39m paris_null\u001b[38;5;241m.\u001b[39miloc[[\u001b[38;5;241m0\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[96], line 75\u001b[0m, in \u001b[0;36mgdf_to_sql_new\u001b[0;34m(gdf, table_name)\u001b[0m\n\u001b[1;32m     72\u001b[0m     [sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(row\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) VALUES (\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m     [sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(row\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m);\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 75\u001b[0m test_row\u001b[38;5;241m.\u001b[39mapply(write_insert, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/radian/lib/python3.11/site-packages/geopandas/geodataframe.py:1586\u001b[0m, in \u001b[0;36mGeoDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;129m@doc\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1586\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m   1587\u001b[0m         func, axis\u001b[38;5;241m=\u001b[39maxis, raw\u001b[38;5;241m=\u001b[39mraw, result_type\u001b[38;5;241m=\u001b[39mresult_type, args\u001b[38;5;241m=\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1588\u001b[0m     )\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;66;03m# pandas <1.4 re-attach last geometry col if lost\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1591\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mPANDAS_GE_14\n\u001b[1;32m   1592\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, GeoDataFrame)\n\u001b[1;32m   1593\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_geometry_column_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/radian/lib/python3.11/site-packages/pandas/core/frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10360\u001b[0m )\n\u001b[0;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/radian/lib/python3.11/site-packages/pandas/core/apply.py:914\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# raw\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/radian/lib/python3.11/site-packages/pandas/core/apply.py:1019\u001b[0m, in \u001b[0;36mFrameApply.apply_raw\u001b[0;34m(self, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(result)\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1019\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\n\u001b[1;32m   1020\u001b[0m         wrap_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis,\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m   1025\u001b[0m     )\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# TODO: mixed type case\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/radian/lib/python3.11/site-packages/numpy/lib/shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    377\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    378\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m res \u001b[38;5;241m=\u001b[39m asanyarray(func1d(inarr_view[ind0], \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[1;32m    385\u001b[0m buff \u001b[38;5;241m=\u001b[39m zeros(inarr_view\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m res\u001b[38;5;241m.\u001b[39mshape, res\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/radian/lib/python3.11/site-packages/pandas/core/apply.py:998\u001b[0m, in \u001b[0;36mFrameApply.apply_raw.<locals>.wrap_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 998\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1000\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n",
      "Cell \u001b[0;32mIn[96], line 72\u001b[0m, in \u001b[0;36mgdf_to_sql_new.<locals>.write_insert\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_insert\u001b[39m(row):\n\u001b[1;32m     71\u001b[0m     sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m     [sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(row\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) VALUES (\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m     [sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(row\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m sqlFile\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m);\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import exrex\n",
    "\n",
    "paris_null = gpd.read_file('/home/paddy/git/radian/geojson_polygons/GeoJSON/null_testing.geojson')\n",
    "directory = os.path.dirname(\"geojson_polygons/paris.geojson\")\n",
    "\n",
    "def gdf_to_sql_new(gdf, table_name):\n",
    "\n",
    "    ###### SQL BOILER PLATE ######\n",
    "    \n",
    "    # Opens up an SQL file based on the table name, writes to the file and closes it\n",
    "    sqlFile = open(f'{directory}/SQL/{table_name}.sql', \"w\")\n",
    "    sqlFile.write(\"\")\n",
    "    sqlFile.close()\n",
    "\n",
    "    # Opens up the SQL file to append lines to it\n",
    "    sqlFile = open(f'{directory}/SQL/{table_name}.sql', \"a\")\n",
    "\n",
    "    # SQL statments to create the table as well as drop if exists the table are appended\n",
    "    sqlFile.write('-- This is an automatically generated SQL table. This has been generated by the RADIAN tool (developer Mr. Paddy Gorry)\\n\\n')\n",
    "\n",
    "    sqlFile.write('DROP TABLE IF EXISTS {}; \\n\\n'.format(table_name))\n",
    "\n",
    "    sqlFile.write('CREATE TABLE {} ( \\n'.format(table_name))\n",
    "    sqlFile.write('\\tpkid SERIAL PRIMARY KEY NOT NULL, \\n')\n",
    "\n",
    "    ###### BOILER PLATE ENDS ######\n",
    "\n",
    "    def get_var_type(dtype):\n",
    "        match dtype:\n",
    "            case 'int64':\n",
    "                return \"INTEGER\"\n",
    "            case 'float64':\n",
    "                return \"REAL\"\n",
    "            case 'object':\n",
    "                return \"VARCHAR\"\n",
    "            case 'datetime64[ns]':\n",
    "                return \"TIMESTAMP\"\n",
    "            case 'geometry':\n",
    "                return \"GEOMETRY DEFAULT ST_GeomFromText('POINT(0,51)', 4326)\"\n",
    "            case _:\n",
    "                return \"NONE\"    \n",
    "\n",
    "    def ddl_column(col):\n",
    "        return f\"\\t{col.name} {get_var_type(col.dtype)}\"\n",
    "        \n",
    "    ###### DDL statements for creating variables from the gdf columns ######\n",
    "    gdf.columns = ['thegeom' if x=='geometry' else x for x in gdf.columns]\n",
    "    gdf_cols = [(gdf[gdf.columns[x]]) for x in range(1,len(gdf.columns))]\n",
    "\n",
    "    # 'geometry' is not a valid column name for the SQL file, so we check and change this\n",
    "    geom_col_name = [col.name for col in gdf_cols if col.dtype=='geometry'][0]\n",
    "\n",
    "    # PKID serial has already been created\n",
    "    for i, col in enumerate(gdf_cols):\n",
    "        sqlFile.write(\"{}{}\".format(ddl_column(col), (\",\\n\" if i < len(gdf.columns)-2 else \"\\n);\"))) #-2 since we omit the first column (pkid)\n",
    "\n",
    "    sqlFile.write('\\n\\n-- Spatial index is now created\\n\\n')\n",
    "\n",
    "    # Creation of Spatial Index for the SQL file\n",
    "    sqlFile.write(f\"CREATE INDEX {table_name}_spatial_index ON {table_name} USING gist ({geom_col_name}); \\n\")\n",
    "\n",
    "    test_row = gdf.iloc[[0]]\n",
    "\n",
    "    ###### DDL Insert Statements ######\n",
    "    def write_insert(row):\n",
    "        sqlFile.write(f\"INSERT INTO {table_name} (\")\n",
    "        [sqlFile.write(f\"{col}, \") if i < len(row.columns)-1 else sqlFile.write(f\"{col}) VALUES (\") for i, col in enumerate(row.columns) if i > 0]\n",
    "        [sqlFile.write(f\"{val}, \") if i < len(row.values[0])-1 else sqlFile.write(f\"{val});\\n\") for i, val in enumerate(row.values[0]) if i > 0]\n",
    "\n",
    "\n",
    "gdf_to_sql_new(paris_null, \"sql_test\")\n",
    "\n",
    "test = [(paris_null[paris_null.columns[x]]) for x in range(1,len(paris_null.columns))]\n",
    "test_row = paris_null.iloc[[0]]\n",
    "\n",
    "print([val for val in test_row.values[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
